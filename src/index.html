<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Egghunt</title>
  <!-- import aframe and then ar.js with image tracking / location based features -->
  <script src="https://aframe.io/releases/1.0.4/aframe.min.js"></script>
  <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js"></script>

  <!-- style for the loader -->
  <style>
    .arjs-loader {
      height: 100%;
      width: 100%;
      position: absolute;
      top: 0;
      left: 0;
      background-color: rgba(0, 0, 0, 0.8);
      z-index: 9999;
      display: flex;
      justify-content: center;
      align-items: center;
    }

    .arjs-loader div {
      text-align: center;
      font-size: 1.25em;
      color: white;
    }
  </style>
</head>

<body style="margin : 0px; overflow: hidden;">
  <!-- minimal loader shown until image descriptors are loaded. Loading may take a while according to the device computational power -->

  <!-- a-frame scene -->
  <a-scene vr-mode-ui="enabled: false;" renderer="logarithmicDepthBuffer: true;" embedded
    arjs="trackingMethod: best; sourceType: webcam;debugUIEnabled: false;">

    <a-entity socket></a-entity>

    <!-- a-nft is the anchor that defines an Image Tracking entity -->
    <!-- on 'url' use the path to the Image Descriptors created before. -->
    <!-- the path should end with the name without the extension e.g. if file is trex.fset' the path should end with trex -->
    <a-marker type="barcode" value="0">
      <a-box id="cubeEl" color="#fe0" opacity="0.6" position="0 0.6 0" >
      </a-box>
    </a-marker>
    <a-entity camera></a-entity>

    <!-- static camera that moves according to the device movemenents -->
  </a-scene>
</body>

</html>